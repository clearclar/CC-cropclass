// Ways for the analysis of AGRICULTURAL FIELDS IN GOOGLE EARTH ENGINE
// 0 SCRIPT SETUP
var aoi = ee.Geometry.Polygon([[[-90.04048449840815, 36.736785343208915],
          [-90.04048449840815, 36.43685428807831],
          [-89.6916685804394, 36.43685428807831],
          [-89.6916685804394, 36.736785343208915]]], null, false);

Map.style().set('cursor', 'crosshair');
Map.centerObject(aoi, 10);

// Add a title to the map.
var title = ui.Label('Crop type classification in Missouri, United States', {
  stretch: 'horizontal', textAlign: 'center', fontWeight: 'bold', fontSize: '16px'
});
Map.add(title);

// Political boundaries of Missouri.
var Missouri = ee.FeatureCollection("FAO/GAUL/2015/level1").filter('ADM1_NAME == "Missouri"');

// ESA landcover product for masking the croptype layer to only agricultural fields.
var ESAlandcover = ee.Image('ESA/WorldCover/v100/2020');

// 1 CROPTYPE PRODUCTS AND TREND ANALYSIS
// Time series chart and trend line of cotton field area within the area of interest 
// show that cotton field area stayed relatively stable since 2001.
var trend_chart = ui.Chart.image.series({
  imageCollection: ee.ImageCollection('USDA/NASS/CDL')
    .filter(ee.Filter.calendarRange(2001, 2023, 'year'))
    .select('cropland').map(function(image){
    return image.addBands(ee.Image.pixelArea().divide(1000000)).updateMask(image.eq(2));
  }).select('area'),
  region: aoi,
  reducer: ee.Reducer.sum(),
  scale: 30
}).setChartType('ScatterChart')
  .setOptions({
    title: 'Annual cotton area for the area of interest in Missouri',
    vAxis: {title: 'Cotton area [sq km]'},
    hAxis: {title: 'Year'},
    pointSize: 2,
    lineSize: 1,
    trendlines: {0: {color: 'red'}}

  });

print('Annual cotton area for the area of interest\nin Missouri from 2001 to 2023', trend_chart, 'Cotton field area decreased slightly\nby around -1.8 km^2 per year');

// Add croptype classification for 2019 and 2023 to the map.
// Switching the layers on and off visualizes changes between the years
var croplandList = ee.List(['2019', '2023']).map(function(year){
  var UScropland = ee.ImageCollection('USDA/NASS/CDL')
                    .filterDate(ee.Date(year), ee.Date(year).advance(1, 'year'))
                    .first()
                    .select('cropland')
                    .clip(aoi)
                    .updateMask(ESAlandcover.eq(40));
  
  return UScropland;
});

print('Total area of agricultural fields within the area of interest in km^2:', ee.Image(croplandList.get(0)).geometry().area().divide(1000000));
Map.addLayer(ee.Image(croplandList.get(0)), {}, 'US cropland 2019');
Map.addLayer(ee.Image(croplandList.get(1)), {}, 'US cropland 2023', false);

// create a binary layer for cotton and non-cotton fields.
var UScotton_2019 = ee.Image(croplandList.get(0)).eq(2);

// 2 DATA IMPORT AND PROCESSING
// 2019 was selected as year of interest. 
// May to November are the months of main growing activity for cotton.
var startMonth = 5;
var endMonth = 11;
var year = 2019;

// Function for single image cloud masking.
function mask_clouds(img) {
  var clouds = ee.Image(img.get('cloud_mask')).select('probability');
  var cloudfree = clouds.lt(MAX_CLOUD_PROBABILITY);
  return img.updateMask(cloudfree);
}

// Inlcuding masks from the 20m and 60m bands ensures excluding cloudy data at scene edges.
function maskEdges(s2_img) {
  return s2_img.updateMask(
    // get the image mask and update it to ...
      s2_img.select('B8A').mask().updateMask(s2_img.select('B9').mask()));
}

// 2nd type of cloud-masking, function for masking clouds and cloud shadow
var masks2clouds = function(image){
  var scl = image.select('SCL');
  // Selecting the cloud shadow and cloud masks (3,7,8,9);
  var cloud_shadow = scl.eq(3);
  var cloud_low = scl.eq(7);
  var cloud_medium = scl.eq(8);
  var cloud_high = scl.eq(9);
  // Merging the masks together
  var cloud_mask = cloud_shadow.add(cloud_low).add(cloud_medium).add(cloud_high);
  // Creating a uniary mask image from the binary mask image i.e. replacing the black with nulls
  var cloud_uni = cloud_mask.eq(0).selfMask();
  // Finally masking the orignal image (or bands) with cloud mask
  return image.updateMask(cloud_uni).copyProperties(image);
};

// Filter input collections by desired data range and region.
var col_criteria = ee.Filter.and(
    ee.Filter.bounds(aoi),
    ee.Filter.calendarRange(startMonth,endMonth,'month'));

// Apply indices.
function addNDVI(image){
  var nd = image.normalizedDifference(['B8', 'B4']).rename('NDVI');
  return image.addBands(nd);
  }

// bare soil index function from https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/barren_soil/
function addBSI(image){
  return image.addBands(image.expression(
    '(B11 + B4) - (B8 + B2)/(B11 + B4) + (B8 + B2)',{
      'B11': image.select('B11'),
      'B4': image.select('B4'),
      'B8': image.select('B8'),
      'B2': image.select('B2'),
    }).divide(10000).rename('BSI') 
    )}

// Function to mosaic images of the same date.
function mosaicByDate(imcol){
  var imlist = imcol.toList(imcol.size());
  var unique_dates = imlist.map(function(im){
    return ee.Image(im).date().format("YYYY-MM-dd");
  }).distinct();
  var mosaic_imlist = unique_dates.map(function(d){
    d = ee.Date(d);
    var im = imcol
      .filterDate(d, d.advance(1, "day"))
      .mosaic();
    return im.set(
      "system:time_start", d.millis(), 
      "system:id", d.format("YYYY-MM-dd"), 
      "system:index", d.format("YYYY-MM-dd"));
    });
  return ee.ImageCollection(mosaic_imlist);
}

// Visualisation parameters for the classified image.
var classVis = {min: 0, max: 1, palette: ['blue' ,'red']};

// Visualisation parameters for an RGB image.
var rgbVis = {bands:['B4', 'B3', 'B2'], min:0, max:3000};

// 2.1 OPTICAL IMAGERY
// apply cloud masking based on the Sentinel-2 cloud probability product by Copernicus
// code source: https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_CLOUD_PROBABILITY
// maximum cloud probability set to 65%
var MAX_CLOUD_PROBABILITY = 65;

// define Sentinel-2 image collection
var S2collection = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
  .filter(col_criteria)
  .filterDate(year+'-01-01',year+'-12-31')
  .map(maskEdges);

var S2cloud_collection = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')
  .filter(col_criteria)
  .filterDate(year+'-01-01',year+'-12-31');

// Join S2 SR with cloud probability dataset to add cloud mask.
var S2combined_cloud = ee.Join.saveFirst('cloud_mask').apply({
  primary: S2collection,
  secondary: S2cloud_collection,
  condition:
      ee.Filter.equals({leftField: 'system:index', rightField: 'system:index'})
});

// Filter collection for cloudy pixel percentage, add a second cloud masking algorithm,
// add an NDVI band and a BSI band, then clip to the area of interest.
var S2_cloud_masked = ee.ImageCollection(S2combined_cloud)
  .map(mask_clouds)
  .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', 25))
  .map(masks2clouds)
  .map(addNDVI)
  .map(addBSI)
  .map(function(image){
    return image.clip(aoi);
  });

// mosaic the images in the collection by date and select only the spectral bands, BSI and NDVI.
var mosaiced_2019 = mosaicByDate(S2_cloud_masked).select(['B.*', 'NDVI']);
Map.addLayer(mosaiced_2019.median(), rgbVis, 'S2 surface reflectance for 2019 masked at ' + MAX_CLOUD_PROBABILITY + '%', false);

// 2.2 RADAR IMAGERY
// Radar imagery has been proven useful as an adittion in landcover classification
// SAR processing functions for Sentinel-1 data from S. BUCHELT & T. ULLMANN 2022
// https://code.earthengine.google.com/171f947ac683a70e9af87a226f7db997
var selectedOrbitMode = 'ASCENDING';
var resampleSize = 10;
var specklefilterSize = 15;

// functions to convert from/to dB
function toNatural(img) {
  var converted = ee.Image(10.0).pow(img.select([0,1]).divide(10.0));
  return converted.copyProperties(img).copyProperties(img, ['system:time_start']).copyProperties(img, ['system:DOY']);
}
function toDB(img) {
  return ee.Image(img).log10().multiply(10.0).copyProperties(img).copyProperties(img, ['system:time_start']);
}

// Median filter.
var filterSpeckles = function(img) {
  var smoothed = img.focal_median(specklefilterSize,'square','meters'); 
  return smoothed.copyProperties(img).copyProperties(img, ['system:time_start']);
};

var resample = function(image) {
  var epsg = imgVV.first().select(0).projection().crs();
  var resampled = image.resample("bilinear")
    .reproject({crs: epsg, scale: resampleSize});
  return resampled;
};

// Additional Border Noise Removal (mask out angles >= 45.23993).
var maskAngLT452 = function(image) {
 var ang = image.select(['angle']);
 return image.updateMask(ang.lt(45.23993)).set('system:time_start', image.get('system:time_start'));
};

// Function to mask out edges of images using angle (mask out angles <= 30.63993).
var maskAngGT30 = function(image) {
 var ang = image.select(['angle']);
 return image.updateMask(ang.gt(30.63993)).set('system:time_start', image.get('system:time_start'));
};

// Remove edges.
var maskEdge = function(image) {
  var mask = image.select(0).unitScale(-25, 5).multiply(255).toByte();
  return image.updateMask(mask.select(0)).set('system:time_start', image.get('system:time_start'));  
};

var f_mask_edges = function(image) {
  var output = maskAngGT30(image);
  output = maskAngLT452(output);
  return output;
};

var border_noise_removal = function (collection){
  return collection.map(f_mask_edges);
};

// Determine the possible relative orbits and select the first one for consistency.
var imgVV = ee.ImageCollection('COPERNICUS/S1_GRD')
  .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))
  .filter(ee.Filter.eq('instrumentMode', 'IW'))
  .filter(ee.Filter.eq('orbitProperties_pass', selectedOrbitMode))
  .filter(ee.Filter.eq('resolution', 'H'));
imgVV = imgVV.select('VV', 'angle')
  .filterBounds(aoi)
  .filterDate(year+'-01-01',year+'-12-31');
var relativeOrbits = ee.List(imgVV.aggregate_array("relativeOrbitNumber_stop").distinct());
var relOrb = relativeOrbits.get(0);

var imgVV_VH = ee.ImageCollection('COPERNICUS/S1_GRD')
  .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))
  .filter(ee.Filter.eq('instrumentMode', 'IW'))
  .filter(ee.Filter.eq('orbitProperties_pass', selectedOrbitMode))
  .filter(ee.Filter.eq('resolution', 'H'))
  .filter(ee.Filter.eq('relativeOrbitNumber_stop', relOrb))
  .select('VV','VH' , 'angle')
  .filterBounds(aoi)
  .filterDate(year+'-01-01',year+'-12-31');

// Border noise removal.
imgVV_VH = border_noise_removal(imgVV_VH);

// Convert to linear.
imgVV_VH = imgVV_VH.map(toNatural);
// MEDIAN FILTER
imgVV_VH = imgVV_VH.map(filterSpeckles);

// Resample to new pixel size.
imgVV_VH = imgVV_VH.map(resample);

// Convert back to dB.
imgVV_VH = imgVV_VH.map(toDB);

// Mosaic.
imgVV_VH = mosaicByDate(imgVV_VH);

var s1_processed_collection = imgVV_VH.map(function(image){
    return image.clip(aoi);
  });

Map.addLayer(s1_processed_collection.median().select('VH'), {min:-30, max:0}, 'S1 median 2019 VH', 0);
Map.addLayer(s1_processed_collection.median().select('VV'), {min:-30, max:0}, 'S1 median 2019 VV', 0);

// cotton chart for S1 data
var cotton_chart = ui.Chart.image.series({
  imageCollection: s1_processed_collection.map(function(image){
    return image.updateMask(UScotton_2019.eq(1));
  }),
  region: aoi,
  reducer: ee.Reducer.median(),
  scale: 20,
}).setChartType('LineChart')
  .setOptions({
      lineWidth: 1,
      pointSize: 2,
      title: 'Cotton field backscatter over time',
      vAxis: {title: 'backscatter intensity [dB]'},
      hAxis: {title: '', format: 'YYYY-MMM', gridlines: {count: 12}},
      series: {
        0: {color: 'red'},
        1: {color: 'blue'}
      },
    });

// non-cotton chart for S1 data
var non_cotton_chart = ui.Chart.image.series({
  imageCollection: s1_processed_collection.map(function(image){
    return image.updateMask(UScotton_2019.eq(0));
  }),
  region: aoi,
  reducer: ee.Reducer.median(),
  scale: 20,
}).setChartType('LineChart')
  .setOptions({
      lineWidth: 1,
      pointSize: 2,
      title: 'Other crop backscatter over time',
      vAxis: {title: 'backscatter intensity [dB]'},
      hAxis: {title: '', format: 'YYYY-MMM', gridlines: {count: 12}},
      series: {
        0: {color: 'red'},
        1: {color: 'blue'}
      },
    });

// Print the charts
print('Charts, visualizing median backscatter over cotton and\nnon-cotton fields for VV and VH polarization',
  cotton_chart, non_cotton_chart);

// 3 VISUALISATION OF SATELLITE IMAGERY SHOWS HOW SPECTRAL PROPERTIES CHANGE OVER THE COURSE OF THE YEAR
// Define GIF visualization parameters.
var gifParams = {
  'region': aoi,
  'dimensions': 300,
  'crs': 'EPSG:3857',
  'framesPerSecond': 1
};

var text_package = require('users/gena/packages:text'); // Import gena's package which allows text overlay on image
var annotation_spot = ee.Geometry.Point([-90.01439196911146,36.46545857507958]);
var annotations = [{position: 'top', offset: '1%', margin: '1%', property: 'system:index', scale: 250}]
  
function addText(image){
  return text_package.annotateImage(image, {}, annotation_spot, annotations); 
}

// Create RGB visualization images for use as animation frames.
var S2Vis = mosaiced_2019.map(function(img) {
  return img.visualize(rgbVis);
}).map(addText);

// Print the GIF URL to the console.
print('Link to GIF of S2 time series', S2Vis.getVideoThumbURL(gifParams));

/// GIF button for Sentinel-2 GIF on Map
var GIF_S2 = ui.Button({label: 'Create Sentinel-2 GIF 2019',
  onClick: function GIF(){
    Map.add(ui.Thumbnail({image: S2Vis, params: gifParams, style: {position: 'bottom-right'}}));
    }, 
  style: {position: 'top-right'}
});
Map.add(GIF_S2);

// Create visualization for S1 images for use as animation frames.
// Date annotation was not possible on radar images because of processing and memory capacities.
var S1Vis_VV = s1_processed_collection.select('VV').map(function(img) {
  return img.visualize({min:-15, max:-5});
});

// Print the GIF URL to the console.
print('Link to GIF of S1 VV time series', S1Vis_VV.getVideoThumbURL(gifParams));

/// GIF button for Sentinel-1 GIF on Map
var GIF_S1_VV = ui.Button({label: 'Create Sentinel-1 VV GIF 2019',
  onClick: function GIF(){
    Map.add(ui.Thumbnail({image: S1Vis_VV, params: gifParams, style: {position: 'bottom-right'}}));
    }, 
  style: {position: 'top-right'}
});
Map.add(GIF_S1_VV);

// Create visualization for S1 images for use as animation frames.
var S1Vis_VH = s1_processed_collection.select('VH').map(function(img) {
  return img.visualize({min:-25, max:-10});
});

// Print the GIF URL to the console.
print('Link to GIF of S1 VH time series', S1Vis_VH.getVideoThumbURL(gifParams));

/// GIF button for Sentinel-1 GIF on Map
var GIF_S1_VH = ui.Button({label: 'Create Sentinel-1 VH GIF 2019',
  onClick: function GIF(){
    Map.add(ui.Thumbnail({image: S1Vis_VH, params: gifParams, style: {position: 'bottom-right'}}));
    }, 
  style: {position: 'top-right'}
});
Map.add(GIF_S1_VH);

// 4 CROP CLASSIFICATION
// Create an image for classification that contains one band for each month within the selected time frame in 2019.
// An image including and one without Sentinel-1 imagery are created to enable comparison of the classification accuracy.
// The images serve as the source for training and prediction.
var img_without = mosaiced_2019.filter(ee.Filter.calendarRange(7,7, 'month')).median()
  .addBands(mosaiced_2019.filter(ee.Filter.calendarRange(8,8, 'month')).median())
  .addBands(mosaiced_2019.filter(ee.Filter.calendarRange(9,9, 'month')).median())
  .addBands(mosaiced_2019.filter(ee.Filter.calendarRange(10,10, 'month')).median());

var img_with = mosaiced_2019.filter(ee.Filter.calendarRange(7,7, 'month')).median()
  .addBands(mosaiced_2019.filter(ee.Filter.calendarRange(8,8, 'month')).median())
  .addBands(mosaiced_2019.filter(ee.Filter.calendarRange(9,9, 'month')).median())
  .addBands(mosaiced_2019.filter(ee.Filter.calendarRange(10,10, 'month')).median())
  .addBands(s1_processed_collection.filter(ee.Filter.calendarRange(7,7, 'month')).median())
  .addBands(s1_processed_collection.filter(ee.Filter.calendarRange(8,8, 'month')).median())
  .addBands(s1_processed_collection.filter(ee.Filter.calendarRange(9,9, 'month')).median())
  .addBands(s1_processed_collection.filter(ee.Filter.calendarRange(10,10, 'month')).median());

// Crop classification product used as label source in classifier training.
var label = 'lc';
var lc = UScotton_2019.rename(label).toByte();

// Classification without Sentinel-1 data.
// Add crop type as a band and sample 200 pixels at 10 m scale 
// from each land cover class within the aoi.
var sample = img_without.addBands(lc).stratifiedSample({
  numPoints: 200,
  classBand: label,
  region: aoi,
  scale: 10,
  geometries: true,
  tileScale: 4
});

// Add a random value field to the sample and use it to approximately split 80%
// of the features into a training set and 20% into a validation set.
sample = sample.randomColumn();
var trainingSample = sample.filter('random <= 0.8');
var validationSample = sample.filter('random > 0.8');

// Train a 10-tree random forest classifier from the training sample.
var trainedClassifier = ee.Classifier.smileRandomForest(10).train({
  features: trainingSample,
  classProperty: label,
  inputProperties: img_without.bandNames(),
});

// Get information about the trained classifier.
print('Results of trained classifier without S1 data', trainedClassifier.explain());
// Get overall accuracy for the S1 training sample.
var trainAccuracy = trainedClassifier.confusionMatrix();
// Get overall accuracy for the validation sample.
validationSample = validationSample.classify(trainedClassifier);
var validationAccuracy = validationSample.errorMatrix(label, 'classification');
print('Training overall accuracy without S1 data', trainAccuracy.accuracy(), '',
  'Validation accuracy without S1 data', validationAccuracy.accuracy());

// Classify the reflectance image from the trained classifier.
var imgClassified = img_without.classify(trainedClassifier);

Map.addLayer(imgClassified, classVis, 'Classified cotton fields without S1 data');

// Classification including S1 data
var sample = img_with.addBands(lc).stratifiedSample({
  numPoints: 200,
  classBand: label,
  region: aoi,
  scale: 10,
  geometries: true,
  tileScale: 4
});

// Add a random value field to the sample and use it to approximately split 80%
// of the features into a training set and 20% into a validation set.
sample = sample.randomColumn();
var trainingSample = sample.filter('random <= 0.8');
var validationSample = sample.filter('random > 0.8');

// Train a 10-tree random forest classifier from the training sample.
var trainedClassifier = ee.Classifier.smileRandomForest(10).train({
  features: trainingSample,
  classProperty: label,
  inputProperties: img_with.bandNames(),
});

// Get information about the trained classifier.
print('Results of trained classifier with S1 data', trainedClassifier.explain());

// Get overall accuracy for the training sample.
var trainAccuracy = trainedClassifier.confusionMatrix();
// Get overall accuracy for the validation sample.
validationSample = validationSample.classify(trainedClassifier);
var validationAccuracy = validationSample.errorMatrix(label, 'classification');
print('Training overall accuracy with S1 data', trainAccuracy.accuracy(), '',
  'Validation accuracy with S1 data', validationAccuracy.accuracy());

// Classify the reflectance image from the trained classifier.
var imgClassified = img_with.classify(trainedClassifier);

Map.addLayer(imgClassified, classVis, 'Classified cotton fields with S1 data');
